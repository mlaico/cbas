{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copied/adapted this notebook from: <a href=http://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py> PyTorch: Training a Classifier on CIFAR-10</a>\n",
    "Training an image classifier\n",
    "----------------------------\n",
    "\n",
    "We will do the following steps in order:\n",
    "\n",
    "1. Load and normalizing the CBAS-36 training and test datasets using\n",
    "   ``torchvision``\n",
    "2. Define a Convolution Neural Network\n",
    "3. Define a loss function\n",
    "4. Train the network on the training data\n",
    "5. Test the network on the test data\n",
    "\n",
    "1. Loading and normalizing CBAS-36\n",
    "\n",
    "Using ``torchvision``, it’s extremely easy to load CBAS-36.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "    ])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root='images/cbas34_train', transform=transform)\n",
    "\n",
    "# # get index for curriculum sampling\n",
    "# id2idx = {}\n",
    "# for i,img in enumerate(trainset.imgs):\n",
    "#     img_id_str = img[0].split('/')[4].split('.')[0]\n",
    "#     id2idx[img_id_str] = i\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root='images/cbas34_val', transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = trainset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us show some of the training images, for fun.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knife truck bench donut\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nF3pAQEDAGkF4oQcEBASsEfx/RrZZCHHd0tkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111da70b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(tensor):\n",
    "    for t, m, s in zip(tensor, IMAGENET_MEAN, IMAGENET_STD):\n",
    "            t.mul_(s).add_(m)     # unnormalize\n",
    "    npimg = tensor.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define a Convolution Neural Network\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "Copy the neural network from the Neural Networks section before and modify it to\n",
    "take 3-channel images (instead of 1-channel images as it was defined).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://www.researchgate.net/profile/Vladimir_Golovko3/publication/313808170/figure/fig4/AS:552880910368768@1508828489761/Architecture-of-simplified-convolutional-neural-network.ppm>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16*5*5, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 34)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "net = LeNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Define a Loss function and optimizer\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.61s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-3:\n",
      "Process Process-2:\n",
      "Process Process-1:\n",
      "Process Process-4:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/airmanfair/Library/Python/3.6/lib/python/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/airmanfair/Library/Python/3.6/lib/python/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/airmanfair/Library/Python/3.6/lib/python/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/airmanfair/Library/Python/3.6/lib/python/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f2a9c02a88ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msize_curriculum\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msize_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msize_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/airmanfair/Desktop/CS189/Project/cbas/size_curriculum.py\u001b[0m in \u001b[0;36msize_train\u001b[0;34m(training_set, model, loss_fn, optimizer, deviations)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# here's were we get image ids from the torchvision dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mtraining_ids\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mcbas_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mratios\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcbas_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratios\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/airmanfair/Desktop/CS189/Project/cbas/size_curriculum.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# here's were we get image ids from the torchvision dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mtraining_ids\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mcbas_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mratios\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcbas_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratios\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "from size_curriculum import size_train\n",
    "size_train(trainset, net, criterion, optimizer, np.arange(-2.5, 1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Train the network\n",
    "^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "This is when things start to get interesting.\n",
    "We simply have to loop over our data iterator, and feed the inputs to the\n",
    "network and optimize.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 3.507\n",
      "[1,  4000] loss: 3.334\n",
      "[1,  6000] loss: 3.259\n",
      "[1,  8000] loss: 3.160\n",
      "[1, 10000] loss: 3.103\n",
      "[1, 12000] loss: 3.059\n",
      "[2,  2000] loss: 3.000\n",
      "[2,  4000] loss: 2.988\n",
      "[2,  6000] loss: 2.977\n",
      "[2,  8000] loss: 2.962\n",
      "[2, 10000] loss: 2.941\n",
      "[2, 12000] loss: 2.929\n",
      "[3,  2000] loss: 2.877\n",
      "[3,  4000] loss: 2.876\n",
      "[3,  6000] loss: 2.884\n",
      "[3,  8000] loss: 2.879\n",
      "[3, 10000] loss: 2.870\n",
      "[3, 12000] loss: 2.881\n",
      "[4,  2000] loss: 2.821\n",
      "[4,  4000] loss: 2.818\n",
      "[4,  6000] loss: 2.818\n",
      "[4,  8000] loss: 2.818\n",
      "[4, 10000] loss: 2.819\n",
      "[4, 12000] loss: 2.817\n",
      "[5,  2000] loss: 2.721\n",
      "[5,  4000] loss: 2.759\n",
      "[5,  6000] loss: 2.768\n",
      "[5,  8000] loss: 2.775\n",
      "[5, 10000] loss: 2.786\n",
      "[5, 12000] loss: 2.779\n",
      "[6,  2000] loss: 2.698\n",
      "[6,  4000] loss: 2.695\n",
      "[6,  6000] loss: 2.744\n",
      "[6,  8000] loss: 2.722\n",
      "[6, 10000] loss: 2.751\n",
      "[6, 12000] loss: 2.757\n",
      "[7,  2000] loss: 2.661\n",
      "[7,  4000] loss: 2.683\n",
      "[7,  6000] loss: 2.714\n",
      "[7,  8000] loss: 2.702\n",
      "[7, 10000] loss: 2.704\n",
      "[7, 12000] loss: 2.701\n",
      "[8,  2000] loss: 2.627\n",
      "[8,  4000] loss: 2.632\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Test the network on the test data\n",
    "\n",
    "We have trained the network for 2 passes over the training dataset.\n",
    "But we need to check if the network has learnt anything at all.\n",
    "\n",
    "We will check this by predicting the class label that the neural network\n",
    "outputs, and checking it against the ground-truth. If the prediction is\n",
    "correct, we add the sample to the list of correct predictions.\n",
    "\n",
    "Okay, first step. Let us display an image from the test set to get familiar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = net(Variable(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs are energies for the 10 classes.\n",
    "Higher the energy for a class, the more the network\n",
    "thinks that the image is of the particular class.\n",
    "So, let's get the index of the highest energy:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results seem pretty good.\n",
    "\n",
    "Let us look at how the network performs on the whole dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 3744 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks waaay better than chance, which is 2.7% accuracy (randomly picking\n",
    "a class out of 36 classes).\n",
    "Seems like the network learnt something.\n",
    "\n",
    "Hmmm, what are the classes that performed well, and the classes that did\n",
    "not perform well:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(34))\n",
    "class_total = list(0. for i in range(34))\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    for i in range(4):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(34):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so what next?\n",
    "\n",
    "How do we run these neural networks on the GPU?\n",
    "\n",
    "Training on GPU\n",
    "----------------\n",
    "Just like how you transfer a Tensor on to the GPU, you transfer the neural\n",
    "net onto the GPU.\n",
    "This will recursively go over all modules and convert their parameters and\n",
    "buffers to CUDA tensors:\n",
    "\n",
    ".. code:: python\n",
    "\n",
    "    net.cuda()\n",
    "\n",
    "\n",
    "Remember that you will have to send the inputs and targets at every step\n",
    "to the GPU too:\n",
    "\n",
    "::\n",
    "\n",
    "        inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "\n",
    "Why dont I notice MASSIVE speedup compared to CPU? Because your network\n",
    "is realllly small.\n",
    "\n",
    "**Exercise:** Try increasing the width of your network (argument 2 of\n",
    "the first ``nn.Conv2d``, and argument 1 of the second ``nn.Conv2d`` –\n",
    "they need to be the same number), see what kind of speedup you get.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
